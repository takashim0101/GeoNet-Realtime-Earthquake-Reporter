# This web app is built using the Streamlit framework.
# It retrieves the latest earthquake data from the GeoNet API and passes that data to the Google Gemini API.
# It automatically generates reports for experts or the public.
#
# Key Features:
# 1. Retrieves real-time earthquake data from the GeoNet API and caches the data.
# 2. Plots earthquake data on a map and visualizes it in interactive charts.
# 3. Lets LLM create reports based on user personas (e.g., real estate agents).
# 4. Beautifully formats and displays the structured JSON data returned by LLM.
#


# This app integrates real-time seismic data from GeoNet with population context from Stats NZ to
# generate localized impact reports using a local LLM. It adjusts messaging based on population density and
# gracefully handles missing data, making it ideal for public sector use and educational outreach.

import streamlit as st
import requests
from datetime import datetime
import json
import pandas as pd
import altair as alt
import time
import os
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

#---------------------------------------------------------------------------------------------------
# 1. Setting the API key and API call function
#---------------------------------------------------------------------------------------------------

@st.cache_data(ttl=300)# Cache for 5 minutes instead of 30 seconds
def fetch_latest_earthquakes():
    """
    Fetch latest earthquake data from GeoNet API.
    Data is cached for 5 minutes to reduce API load.
    """
    api_url = "https://api.geonet.org.nz/quake?MMI=3"
    
    try:
        response = requests.get(api_url)
        response.raise_for_status()
        data = response.json()
        
        earthquakes = []
        for feature in data['features'][:5]:
            props = feature['properties']
            time_utc = datetime.fromisoformat(props['time'].replace('Z', '+00:00'))
            
            earthquakes.append({
                "ID": props['publicID'],
                "Location": props['locality'],
                "Magnitude": props['magnitude'],
                "Depth (km)": props['depth'],
                "Shaking Intensity (MMI)": props['mmi'],
                "Time (NZST)": time_utc.strftime('%Y-%m-%d %H:%M:%S'),
                "latitude": feature['geometry']['coordinates'][1],
                "longitude": feature['geometry']['coordinates'][0]
            })
        return earthquakes
    except requests.exceptions.RequestException as e:
        st.error(f"Error accessing GeoNet API: {e}")
        return None

def call_llm_api(prompt):
    """
    Calls a local Ollama model to generate a response in a structured JSON format.
    Assumes Ollama is running at http://localhost:11434.
    """
    url = "http://127.0.0.1:11434/api/generate"
    headers = {
        "Content-Type": "application/json",
    }
    
    # Define the model to use. Make sure you have this model pulled in Ollama.
    # You can change "llama3" to any other model you have available.
    model_name = "llama3"

    # The prompt already asks for a JSON output, which is good.
    # Ollama's `generate` endpoint expects a `prompt` field.
    # The `format: "json"` parameter helps ensure the output is valid JSON.
    payload = {
        "model": model_name,
        "prompt": prompt,
        "format": "json", # Request JSON output from Ollama
        "stream": False
    }

    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload))
        response.raise_for_status()
        
        # Ollama (with format: "json") returns a JSON object where the 'response' field contains the JSON string.
        ollama_response = response.json()
        json_string = ollama_response.get('response')

        if json_string:
            try:
                # The response itself is a JSON string, so we parse it again.
                llm_data = json.loads(json_string)
                return llm_data
            except json.JSONDecodeError:
                return {"error": "Failed to parse the JSON content from the LLM response."}
        else:
            return {"error": "The API returned an empty or malformed response."}

    except requests.exceptions.RequestException as e:
        st.error(f"Error connecting to Ollama API: {e}. Is Ollama running?")
        return {"error": "Could not connect to the local LLM server."}
    except Exception as e:
        st.error(f"An unexpected error occurred: {e}")
        return {"error": "An unexpected error occurred while calling the LLM."}

def get_population_data_from_statsnz(longitude, latitude, radius_meters=10000):
    """
    Stats NZ Spatial Query API„Åã„ÇâÊåáÂÆö„Åï„Çå„ÅüÂ∫ßÊ®ôÂë®Ëæ∫„ÅÆ‰∫∫Âè£Èñ¢ÈÄ£„Éá„Éº„Çø„ÇíÂèñÂæó„Åô„ÇãÈñ¢Êï∞„ÄÇ
    """
    api_key = os.getenv("STATS_NZ_API_KEY")
    if not api_key:
        st.warning("STATS_NZ_API_KEY not found in .env file. Population data will not be fetched.")
        return None

    # Layer ID 115044 is assumed to be a population-related boundary layer based on previous search.
    # We need to confirm its exact nature for proper interpretation.
    layer_id = "115044" 
    
    # Stats NZ API expects coordinates in NZTM2000 projection (EPSG:2193)
    # However, the API example uses x and y which typically correspond to longitude and latitude in WGS84 (EPSG:4326)
    # For simplicity, we'll assume the API can handle WGS84 for now, or requires a transformation.
    # If the API truly requires NZTM2000, a coordinate transformation step would be needed here.
    
    api_url = (f"https://datafinder.stats.govt.nz/services/query/v1/vector.json?"
               f"key={api_key}&layer={layer_id}&x={longitude}&y={latitude}&"
               f"max_results=10&radius={radius_meters}&geometry=true&with_field_names=true")
    
    try:
        response = requests.get(api_url)
        response.raise_for_status()
        data = response.json()
        
        if data and 'features' in data:
            # Extract relevant properties from features
            # The exact fields will depend on the layer's schema
            population_info = []
            for feature in data['features']:
                props = feature.get('properties', {})
                # Assuming 'name' and 'population' or similar fields exist
                # This part needs adjustment once we know the exact schema of layer 115044
                population_info.append({
                    "Name": props.get('name', 'N/A'),
                    "Value": props.get('value', 'N/A'), # Placeholder, actual field name needed
                    "Geometry": feature.get('geometry')
                })
            return population_info
        else:
            return None
            
    except requests.exceptions.RequestException as e:
        st.error(f"Error accessing Stats NZ API: {e}")
        return None
    except Exception as e:
        st.error(f"An unexpected error occurred while fetching population data: {e}")
        return None


#---------------------------------------------------------------------------------------------------
# 2. Streamlit UI„ÅÆÊßãÁØâ
#---------------------------------------------------------------------------------------------------

NOTIFICATION_FILE = "notification_status.txt"

def read_notification_status():
    """
    ÈÄöÁü•„Éï„Ç°„Ç§„É´„Åã„Çâ„É°„ÉÉ„Çª„Éº„Ç∏„ÇíË™≠„ÅøËæº„ÇÄÈñ¢Êï∞„ÄÇ
    """
    if os.path.exists(NOTIFICATION_FILE):
        with open(NOTIFICATION_FILE, "r", encoding="utf-8") as f:
            content = f.read().strip()
        if content:
            return content
    return None

# „Çµ„Ç§„Éâ„Éê„Éº„ÇíUI„ÅÆÊï¥ÁêÜ„Å´‰ΩøÁî®
with st.sidebar:
    st.header("App Settings")
    user_persona = st.text_input("Report for:", placeholder="e.g., 'real estate agent' or 'urban planner'")
    st.markdown("---")
    st.header("Project Innovation")
    st.markdown("""
    - **Technical Interest**: Combines **Natural Language (LLM)** & **Geospatial Data (GIS)**.
    - **Interactive Demo**: Dynamic map & customizable reports.
    - **Clear Use Cases**: Adaptable for **real estate agents** & **urban planners**.
    """)
    st.markdown("---")
    st.header("Further Improvements (Concept)")
    st.markdown("- **Notification Feature**: Background alerts for major quakes.")
    st.markdown("- **Historical Data**: Could be expanded to include historical quake analysis.")

st.title("GeoNet Real-time Earthquake Reporter üåè")
st.markdown("This app provides a clear report on the latest GeoNet data, which is **automatically refreshed every 5 minutes**.")

# Read and display notifications from the background scheduler
notification_message = read_notification_status()
if notification_message:
    st.error(notification_message) # Use st.error for major quake alerts

# „Ç¢„Éó„É™„ÅØ„ÄÅ„Ç§„É≥„Çø„É©„ÇØ„Ç∑„Éß„É≥„Åæ„Åü„ÅØ„É™„Éï„É¨„ÉÉ„Ç∑„É•„Åî„Å®„Å´‰∏ä„Åã„Çâ‰∏ã„Å´ÂÆüË°å„Åï„Çå„Çã
st.info(f"Fetching information... (Automatically updates every 5 minutes, last updated: {datetime.now().strftime('%H:%M:%S')})")
quakes = fetch_latest_earthquakes()

if quakes and quakes[0]['Magnitude'] is not None:
    st.subheader("üìç Recent Earthquakes on the Map")
    
    earthquake_df = pd.DataFrame(quakes)
    st.map(earthquake_df, latitude='latitude', longitude='longitude', zoom=4)
    
    st.subheader("üìä Earthquake Magnitude Distribution")
    chart = alt.Chart(earthquake_df).mark_bar().encode(
        x=alt.X('Magnitude:Q', bin=True),
        y='count()',
        tooltip=['Magnitude', 'count()']
    ).properties(
        title='Frequency of Earthquakes by Magnitude'
    )
    st.altair_chart(chart, use_container_width=True)
    
    st.subheader("üìù Latest Earthquake Data")
    st.write(earthquake_df)

    # Fetch and display population data for the latest earthquake
    if quakes:
        latest_quake = quakes[0]
        st.subheader(f"üë• Population Data near {latest_quake['Location']}")
        
        # Assuming longitude and latitude are available in latest_quake
        population_data = get_population_data_from_statsnz(
            latest_quake['longitude'], 
            latest_quake['latitude']
        )
        
        if population_data:
            # For now, just display the raw data.
            # Later, this can be processed into a GeoDataFrame and visualized.
            st.json(population_data) 
        else:
            st.info("No population data found or API key missing for this location.")
    
    with open("llm_prompt.txt", "r", encoding="utf-8") as f:
        prompt_template = f.read()
    
    prompt = prompt_template.replace("{{earthquake_data}}", json.dumps(quakes, indent=2, ensure_ascii=False)) \
                        .replace("{{population_data}}", json.dumps(population_data, indent=2, ensure_ascii=False))
        
    llm_response = call_llm_api(prompt)
    
    st.subheader("ü§ñ LLM Report")
    
    if 'error' in llm_response:
        st.error(llm_response['error'])
    else:
        st.write(f"### {llm_response.get('report_title', 'Report')}")
        st.write(llm_response.get('summary', ''))
        
        if 'impacts' in llm_response:
            impacts_df = pd.DataFrame(llm_response['impacts'])
            st.table(impacts_df)
else:
    st.warning("Could not fetch earthquake data. Please try again later.")

# Add a manual refresh button
if st.button("Refresh data"):
    st.rerun()
